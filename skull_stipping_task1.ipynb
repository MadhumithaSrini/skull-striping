{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skull stipping_task1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install SimpleITK"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KkHmTAKXo_s",
        "outputId": "68d54b72-b227-480a-ad12-34c5ed9c0150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (48.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.4 MB 2.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-tcJG0EQNVX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import path\n",
        "import nibabel as nib\n",
        "from nibabel.testing import data_path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import sys\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "import SimpleITK as sitk\n",
        "from random import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nipype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMtqEtxbCgpg",
        "outputId": "0d2ea124-fc28-4264-cae8-0c84ad2b13dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nipype in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (2.6.3)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (6.1.1)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (3.17.6)\n",
            "Requirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from nipype) (1.3.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from nipype) (1.4.1)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (7.1.2)\n",
            "Requirement already satisfied: traits!=5.0,>=4.6 in /usr/local/lib/python3.7/dist-packages (from nipype) (6.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from nipype) (21.3)\n",
            "Requirement already satisfied: numpy>=1.15.3 in /usr/local/lib/python3.7/dist-packages (from nipype) (1.21.5)\n",
            "Requirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (3.6.0)\n",
            "Requirement already satisfied: prov>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from nipype) (2.0.0)\n",
            "Requirement already satisfied: etelemetry>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (0.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.7/dist-packages (from nipype) (2.8.2)\n",
            "Requirement already satisfied: nibabel>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from nipype) (3.0.2)\n",
            "Requirement already satisfied: ci-info>=0.2 in /usr/local/lib/python3.7/dist-packages (from etelemetry>=0.2.0->nipype) (0.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from etelemetry>=0.2.0->nipype) (2.23.0)\n",
            "Requirement already satisfied: lxml>=3.3.5 in /usr/local/lib/python3.7/dist-packages (from prov>=1.5.2->nipype) (4.2.6)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot>=1.2.3->nipype) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.2->nipype) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib>=5.0.0->nipype) (0.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib>=5.0.0->nipype) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from rdflib>=5.0.0->nipype) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=5.0.0->nipype) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->rdflib>=5.0.0->nipype) (3.10.0.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->etelemetry>=0.2.0->nipype) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->etelemetry>=0.2.0->nipype) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->etelemetry>=0.2.0->nipype) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nilearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg3mN_jfH6w9",
        "outputId": "52087d79-cbb3-414d-a073-6712e4198c1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nilearn\n",
            "  Downloading nilearn-0.9.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.0.2)\n",
            "Requirement already satisfied: nibabel>=2.5 in /usr/local/lib/python3.7/dist-packages (from nilearn) (3.0.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.1.0)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from nilearn) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->nilearn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->nilearn) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->nilearn) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2->nilearn) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21->nilearn) (3.1.0)\n",
            "Installing collected packages: nilearn\n",
            "Successfully installed nilearn-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nipype.interfaces.ants import N4BiasFieldCorrection"
      ],
      "metadata": {
        "id": "gClh6KoNCmhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdd1xJgej4I1",
        "outputId": "cc826fda-18ca-4ca4-9e25-71b0e15d8362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=nib.load('/content/drive/MyDrive/NFBS_Dataset/A00028185/sub-A00028185_ses-NFB3_T1w.nii.gz')\n",
        "print('Shape of image=',img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDBvivIGSO6r",
        "outputId": "1c9146e0-be9a-47d4-e3cc-c78715460577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of image= (256, 256, 192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#storing the address of 3 types of files\n",
        "brain_mask=[]\n",
        "brain=[]\n",
        "raw=[]\n",
        "for subdir, dirs, files in os.walk('/content/drive/MyDrive/NFBS_Dataset'):\n",
        "    for file in files:\n",
        "        filepath = subdir + os.sep + file\n",
        "        if filepath.endswith(\".gz\"):\n",
        "          if '_brainmask.' in filepath:\n",
        "            brain_mask.append(filepath)\n",
        "          elif '_brain.' in filepath:\n",
        "            brain.append(filepath)\n",
        "          else:\n",
        "            raw.append(filepath)"
      ],
      "metadata": {
        "id": "O-8y5K15mErA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "df['raw'] = raw\n",
        "df['brain'] = brain\n",
        "df['brain_mask'] = brain_mask\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jgscq-Olvsqj",
        "outputId": "efc05681-07dc-49c7-8905-e659ea3cad0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 raw  \\\n",
              "0  /content/drive/MyDrive/NFBS_Dataset/A00063326/...   \n",
              "1  /content/drive/MyDrive/NFBS_Dataset/A00062917/...   \n",
              "2  /content/drive/MyDrive/NFBS_Dataset/A00064081/...   \n",
              "3  /content/drive/MyDrive/NFBS_Dataset/A00062942/...   \n",
              "4  /content/drive/MyDrive/NFBS_Dataset/A00062351/...   \n",
              "\n",
              "                                               brain  \\\n",
              "0  /content/drive/MyDrive/NFBS_Dataset/A00063326/...   \n",
              "1  /content/drive/MyDrive/NFBS_Dataset/A00062917/...   \n",
              "2  /content/drive/MyDrive/NFBS_Dataset/A00064081/...   \n",
              "3  /content/drive/MyDrive/NFBS_Dataset/A00062942/...   \n",
              "4  /content/drive/MyDrive/NFBS_Dataset/A00062351/...   \n",
              "\n",
              "                                          brain_mask  \n",
              "0  /content/drive/MyDrive/NFBS_Dataset/A00063326/...  \n",
              "1  /content/drive/MyDrive/NFBS_Dataset/A00062917/...  \n",
              "2  /content/drive/MyDrive/NFBS_Dataset/A00064081/...  \n",
              "3  /content/drive/MyDrive/NFBS_Dataset/A00062942/...  \n",
              "4  /content/drive/MyDrive/NFBS_Dataset/A00062351/...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a6bd2b49-2b26-4af8-a315-23de078dd701\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw</th>\n",
              "      <th>brain</th>\n",
              "      <th>brain_mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00063326/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00063326/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00063326/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062917/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062917/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062917/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00064081/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00064081/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00064081/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062942/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062942/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062942/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062351/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062351/...</td>\n",
              "      <td>/content/drive/MyDrive/NFBS_Dataset/A00062351/...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6bd2b49-2b26-4af8-a315-23de078dd701')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a6bd2b49-2b26-4af8-a315-23de078dd701 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a6bd2b49-2b26-4af8-a315-23de078dd701');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvlFF-D6nkiY",
        "outputId": "257f1020-c13c-4907-e5f7-7b4f2d2f3fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nilearn.image import resample_img"
      ],
      "metadata": {
        "id": "3wZqZzlpIA-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame()\n",
        "\n",
        "class preprocessing():\n",
        "  def __init__(self,df):\n",
        "    self.data=df\n",
        "    self.raw_index=[]\n",
        "    self.mask_index=[]\n",
        "    \n",
        "    \n",
        "  def n4biasfield_correction(self):\n",
        "    path = '/content/drive/MyDrive/NFBS augmented data'\n",
        "    if(os.path.exists(path)== False):\n",
        "      os.mkdir('/content/drive/MyDrive/NFBS augmented data')\n",
        "      os.mkdir('/content/drive/MyDrive/NFBS augmented data/processed')\n",
        "    path = '/content/drive/MyDrive/NFBS augmented data/processed' \n",
        "\n",
        "    raw1 = []\n",
        "    for i in range(len(self.data)):\n",
        "      img_path = self.data.raw.iloc[i]\n",
        "      mask_path = self.data.brain_mask.iloc[i]\n",
        "      \n",
        "      image = sitk.ReadImage(img_path, sitk.sitkFloat32)\n",
        "      maskImage = sitk.ReadImage(mask_path, sitk.sitkUInt8)\n",
        "    \n",
        "      corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
        "      numberFittingLevels = 4\n",
        "      maxIter = 10\n",
        "      corrector.SetMaximumNumberOfIterations([maxIter] * numberFittingLevels)\n",
        "\n",
        "      corrected_image = corrector.Execute(image, maskImage)\n",
        "\n",
        "      new_path = os.path.join(path,'rawbias'+str(i)+'.nii.gz')\n",
        "      raw1.append(new_path)\n",
        "\n",
        "      sitk.WriteImage(corrected_image, new_path)\n",
        "    \n",
        "    print(\"done appending\")\n",
        "    df1['raw'] = raw1\n",
        "    df1['brain'] = df['brain']\n",
        "    df1['brain_mask'] = df['brain_mask']\n",
        "\n",
        "    self.data = df1\n",
        "    self.raw_index = df1['raw']\n",
        "    print('Bias correction done')\n",
        "    return\n",
        "\n",
        "\n",
        "  '''def resize_crop(self):\n",
        "    #Reducing the size of image due to memory constraints\n",
        "    path = '/content/drive/MyDrive/NFBS augmented data/processed/'\n",
        "    target_shape = np.array((96,128,160))                   #reducing size of image from 256*256*192 to 96*128*160\n",
        "    new_resolution = [2,]*3\n",
        "    new_affine = np.zeros((4,4))\n",
        "    new_affine[:3,:3] = np.diag(new_resolution)\n",
        "\n",
        "    # putting point 0,0,0 in the middle of the new volume - this could be refined in the future\n",
        "\n",
        "    new_affine[:3,3] = target_shape*new_resolution/2.*-1\n",
        "    new_affine[3,3] = 1.\n",
        "    #print(new_affine)\n",
        "\n",
        "    #resizing both image and mask and storing in folder\n",
        "\n",
        "    for i in range(len(self.data)):\n",
        "        downsampled_and_cropped_nii = resample_img(self.data.raw.iloc[i], target_affine=new_affine, target_shape=target_shape, interpolation='nearest')\n",
        "        filename = os.path.join(path+'rawbias'+str(i)+'.nii.gz')\n",
        "        downsampled_and_cropped_nii.to_filename(filename)\n",
        "        filename1 = filename.replace('bias','crop')\n",
        "        os.rename(filename,filename1)\n",
        "        self.raw_index.append(path+'rawcrop'+str(i)+'.nii.gz')\n",
        "        \n",
        "        downsampled_and_cropped_nii = resample_img(self.data.brain_mask.iloc[i], target_affine=new_affine, target_shape=target_shape, interpolation='nearest')\n",
        "        filename = os.path.join(path+'maskcrop'+str(i)+'.nii.gz')\n",
        "        downsampled_and_cropped_nii.to_filename(filename)\n",
        "        filename1 = filename.replace('bias','crop')\n",
        "        os.rename(filename,filename1)\n",
        "        self.mask_index.append(path+'maskcrop'+str(i)+'.nii.gz')\n",
        "\n",
        "    print('Cropping done')\n",
        "    return   '''\n",
        "\n",
        "\n",
        "  def intensity_normalization(self):\n",
        "    path = '/content/drive/MyDrive/NFBS augmented data/processed'\n",
        "    for i in self.raw_index:\n",
        "      #print(i)\n",
        "      image = sitk.ReadImage(i)\n",
        "      resacleFilter = sitk.RescaleIntensityImageFilter()\n",
        "      resacleFilter.SetOutputMaximum(255)\n",
        "      resacleFilter.SetOutputMinimum(0)\n",
        "      image = resacleFilter.Execute(image)\n",
        "      sitk.WriteImage(image,i)\n",
        "      j= i.replace('bias','norm')\n",
        "      os.rename(i,j)\n",
        "    print('Normalization done')\n",
        "    return"
      ],
      "metadata": {
        "id": "_zSQrO-jFjBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obj = preprocessing(df)\n",
        "#obj.n4biasfield_correction()\n",
        "obj.resize_crop()\n",
        "obj.intensity_normalization()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsHZRKpOWFBW",
        "outputId": "ce9ce003-8262-419a-8b7f-1679508f2897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cropping done\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop0.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop1.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop2.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop3.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop4.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop5.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop6.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop7.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop8.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop9.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop10.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop11.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop12.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop13.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop14.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop15.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop16.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop17.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop18.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop19.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop20.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop21.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop22.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop23.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop24.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop25.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop26.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop27.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop28.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop29.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop30.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop31.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop32.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop33.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop34.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop35.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop36.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop37.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop38.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop39.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop40.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop41.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop42.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop43.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop44.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop45.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop46.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop47.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop48.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop49.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop50.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop51.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop52.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop53.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop54.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop55.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop56.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop57.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop58.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop59.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop60.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop61.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop62.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop63.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop64.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop65.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop66.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop67.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop68.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop69.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop70.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop71.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop72.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop73.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop74.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop75.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop76.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop77.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop78.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop79.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop80.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop81.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop82.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop83.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop84.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop85.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop86.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop87.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop88.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop89.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop90.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop91.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop92.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop93.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop94.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop95.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop96.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop97.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop98.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop99.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop100.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop101.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop102.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop103.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop104.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop105.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop106.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop107.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop108.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop109.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop110.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop111.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop112.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop113.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop114.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop115.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop116.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop117.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop118.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop119.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop120.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop121.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop122.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop123.nii.gz\n",
            "/content/drive/MyDrive/NFBS augmented data/processed/rawcrop124.nii.gz\n",
            "Normalization done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img=nib.load('/content/drive/MyDrive/NFBS augmented data/processed/raw0.nii.gz')\n",
        "n1_header = img.header\n",
        "print(n1_header)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-GNgDHDNNLh",
        "outputId": "a78eeb17-e5f9-4059-b4f2-5f54fd61fc81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
            "sizeof_hdr      : 348\n",
            "data_type       : b''\n",
            "db_name         : b''\n",
            "extents         : 0\n",
            "session_error   : 0\n",
            "regular         : b''\n",
            "dim_info        : 0\n",
            "dim             : [  3 256 256 192   1   1   1   1]\n",
            "intent_p1       : 0.0\n",
            "intent_p2       : 0.0\n",
            "intent_p3       : 0.0\n",
            "intent_code     : none\n",
            "datatype        : float32\n",
            "bitpix          : 32\n",
            "slice_start     : 0\n",
            "pixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\n",
            "vox_offset      : 0.0\n",
            "scl_slope       : nan\n",
            "scl_inter       : nan\n",
            "slice_end       : 0\n",
            "slice_code      : unknown\n",
            "xyzt_units      : 0\n",
            "cal_max         : 0.0\n",
            "cal_min         : 0.0\n",
            "slice_duration  : 0.0\n",
            "toffset         : 0.0\n",
            "glmax           : 0\n",
            "glmin           : 0\n",
            "descrip         : b''\n",
            "aux_file        : b''\n",
            "qform_code      : unknown\n",
            "sform_code      : aligned\n",
            "quatern_b       : 0.0\n",
            "quatern_c       : 0.0\n",
            "quatern_d       : 0.0\n",
            "qoffset_x       : -256.0\n",
            "qoffset_y       : -256.0\n",
            "qoffset_z       : -192.0\n",
            "srow_x          : [   2.    0.    0. -256.]\n",
            "srow_y          : [   0.    2.    0. -256.]\n",
            "srow_z          : [   0.    0.    2. -192.]\n",
            "intent_name     : b''\n",
            "magic           : b'n+1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "directory = '/content/drive/MyDrive/NFBS augmented data/processed'\n",
        "\n",
        "raw_path =  '/content/drive/MyDrive/NFBS augmented data/processed/raw'\n",
        "if(os.path.exists(raw_path)== False):\n",
        "  os.mkdir('/content/drive/MyDrive/NFBS augmented data/processed/raw')\n",
        "\n",
        "mask_path = '/content/drive/MyDrive/NFBS augmented data/processed/mask'\n",
        "if(os.path.exists(mask_path)== False):\n",
        "  os.mkdir('/content/drive/MyDrive/NFBS augmented data/processed/mask')\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "  f = os.path.join(directory, filename)\n",
        "  # checking if it is a file\n",
        "  if os.path.isfile(f):\n",
        "      if('raw' in f):\n",
        "        shutil.move(f, raw_path)\n",
        "      elif('mask' in f):\n",
        "        shutil.move(f, mask_path) "
      ],
      "metadata": {
        "id": "NUEZ6X5k5Q9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "-i20ZaeY5RB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def data_gen(img_list, mask_list, batch_size):\n",
        "    '''Custom data generator to feed image to model'''\n",
        "    c = 0\n",
        "    n = [i for i in range(len(img_list))]  #List of training images\n",
        "    random.shuffle(n)\n",
        "    \n",
        "    while (True):\n",
        "      img = np.zeros((batch_size, 96, 128, 160,1)).astype('float')   #adding extra dimensions as conv3d takes file of size 5\n",
        "      mask = np.zeros((batch_size, 96, 128, 160,1)).astype('float')\n",
        "\n",
        "      for i in range(c, c+batch_size): \n",
        "        train_img = nib.load(img_list[n[i]]).get_data()\n",
        "        train_img=np.expand_dims(train_img,-1)\n",
        "\n",
        "        train_mask = nib.load(mask_list[n[i]]).get_data()\n",
        "        train_mask=np.expand_dims(train_mask,-1)\n",
        "\n",
        "        '''augmented = train_transform(image= train_img, mask= train_mask)\n",
        "        train_img = augmented ['image']\n",
        "        train_mask = augmented ['mask']\n",
        "        train_img = image.astype(np.float32)\n",
        "        train_mask = np.repeat(image[..., np.newaxis], 3, -1)  '''\n",
        "        train_img = train_img.astype(np.float32)\n",
        "        train_mask = train_mask.astype(np.float32)\n",
        "\n",
        "        #print(train_img, \" \", train_mask)\n",
        "\n",
        "        img[i-c]=train_img\n",
        "        mask[i-c] = train_mask\n",
        "      c+=batch_size\n",
        "      if(c+batch_size>=len(img_list)):\n",
        "        c=0\n",
        "        random.shuffle(n)\n",
        "\n",
        "    yield img,mask"
      ],
      "metadata": {
        "id": "OHhRL0AXVTJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_gen(train_x,train_y,5)"
      ],
      "metadata": {
        "id": "-KZs_XIpVTMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be192afb-6825-4736-e24c-d9936fc04f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object data_gen at 0x7fd3d4226f50>"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = data_gen(train_x,train_y, batch_size = 5)"
      ],
      "metadata": {
        "id": "LZ7-g1grhGmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras implementation of the paper:\n",
        "# 3D MRI Brain Tumor Segmentation Using Autoencoder Regularization\n",
        "# by Myronenko A. (https://arxiv.org/pdf/1810.11654.pdf)\n",
        "# Author of this code: Suyog Jadhav (https://github.com/IAmSUyogJadhav)\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.losses import mse\n",
        "from keras.layers import Conv3D, Activation, Add, UpSampling3D, Lambda, Dense\n",
        "from keras.layers import Input, Reshape, Flatten, Dropout, SpatialDropout3D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "try:\n",
        "    from group_norm import GroupNormalization\n",
        "except ImportError:\n",
        "    import urllib.request\n",
        "    print('Downloading group_norm.py in the current directory...')\n",
        "    url = 'https://raw.githubusercontent.com/titu1994/Keras-Group-Normalization/master/group_norm.py'\n",
        "    urllib.request.urlretrieve(url, \"group_norm.py\")\n",
        "    from group_norm import GroupNormalization\n",
        "\n",
        "\n",
        "def green_block(inp, filters, data_format='channels_first', name=None):\n",
        "    \"\"\"\n",
        "    green_block(inp, filters, name=None)\n",
        "    ------------------------------------\n",
        "    Implementation of the special residual block used in the paper. The block\n",
        "    consists of two (GroupNorm --> ReLu --> 3x3x3 non-strided Convolution)\n",
        "    units, with a residual connection from the input `inp` to the output. Used\n",
        "    internally in the model. Can be used independently as well.\n",
        "    Parameters\n",
        "    ----------\n",
        "    `inp`: An keras.layers.layer instance, required\n",
        "        The keras layer just preceding the green block.\n",
        "    `filters`: integer, required\n",
        "        No. of filters to use in the 3D convolutional block. The output\n",
        "        layer of this green block will have this many no. of channels.\n",
        "    `data_format`: string, optional\n",
        "        The format of the input data. Must be either 'chanels_first' or\n",
        "        'channels_last'. Defaults to `channels_first`, as used in the paper.\n",
        "    `name`: string, optional\n",
        "        The name to be given to this green block. Defaults to None, in which\n",
        "        case, keras uses generated names for the involved layers. If a string\n",
        "        is provided, the names of individual layers are generated by attaching\n",
        "        a relevant prefix from [GroupNorm_, Res_, Conv3D_, Relu_, ], followed\n",
        "        by _1 or _2.\n",
        "    Returns\n",
        "    -------\n",
        "    `out`: A keras.layers.Layer instance\n",
        "        The output of the green block. Has no. of channels equal to `filters`.\n",
        "        The size of the rest of the dimensions remains same as in `inp`.\n",
        "    \"\"\"\n",
        "    inp_res = Conv3D(\n",
        "        filters=filters,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format=data_format,\n",
        "        name=f'Res_{name}' if name else None)(inp)\n",
        "\n",
        "    # axis=1 for channels_first data format\n",
        "    # No. of groups = 8, as given in the paper\n",
        "    x = GroupNormalization(\n",
        "        groups=8,\n",
        "        axis=1 if data_format == 'channels_first' else 0,\n",
        "        name=f'GroupNorm_1_{name}' if name else None)(inp)\n",
        "    x = Activation('relu', name=f'Relu_1_{name}' if name else None)(x)\n",
        "    x = Conv3D(\n",
        "        filters=filters,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        data_format=data_format,\n",
        "        name=f'Conv3D_1_{name}' if name else None)(x)\n",
        "\n",
        "    x = GroupNormalization(\n",
        "        groups=8,\n",
        "        axis=1 if data_format == 'channels_first' else 0,\n",
        "        name=f'GroupNorm_2_{name}' if name else None)(x)\n",
        "    x = Activation('relu', name=f'Relu_2_{name}' if name else None)(x)\n",
        "    x = Conv3D(\n",
        "        filters=filters,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        data_format=data_format,\n",
        "        name=f'Conv3D_2_{name}' if name else None)(x)\n",
        "\n",
        "    out = Add(name=f'Out_{name}' if name else None)([x, inp_res])\n",
        "    return out\n",
        "\n",
        "\n",
        "# From keras-team/keras/blob/master/examples/variational_autoencoder.py\n",
        "def sampling(args):\n",
        "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
        "    # Arguments\n",
        "        args (tensor): mean and log of variance of Q(z|X)\n",
        "    # Returns\n",
        "        z (tensor): sampled latent vector\n",
        "    \"\"\"\n",
        "    z_mean, z_var = args\n",
        "    batch = K.shape(z_mean)[0]\n",
        "    dim = K.int_shape(z_mean)[1]\n",
        "    # by default, random_normal has mean = 0 and std = 1.0\n",
        "    epsilon = K.random_normal(shape=(batch, dim))\n",
        "    return z_mean + K.exp(0.5 * z_var) * epsilon\n",
        "\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    intersection = K.sum(K.abs(y_true * y_pred), axis=[-3,-2,-1])\n",
        "    dn = K.sum(K.square(y_true) + K.square(y_pred), axis=[-3,-2,-1]) + 1e-8\n",
        "    return K.mean(2 * intersection / dn, axis=[0,1])\n",
        "\n",
        "\n",
        "def loss_gt(e=1e-8):\n",
        "    \"\"\"\n",
        "    loss_gt(e=1e-8)\n",
        "    ------------------------------------------------------\n",
        "    Since keras does not allow custom loss functions to have arguments\n",
        "    other than the true and predicted labels, this function acts as a wrapper\n",
        "    that allows us to implement the custom loss used in the paper. This function\n",
        "    only calculates - L<dice> term of the following equation. (i.e. GT Decoder part loss)\n",
        "    \n",
        "    L = - L<dice> + weight_L2 ∗ L<L2> + weight_KL ∗ L<KL>\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    `e`: Float, optional\n",
        "        A small epsilon term to add in the denominator to avoid dividing by\n",
        "        zero and possible gradient explosion.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    loss_gt_(y_true, y_pred): A custom keras loss function\n",
        "        This function takes as input the predicted and ground labels, uses them\n",
        "        to calculate the dice loss.\n",
        "        \n",
        "    \"\"\"\n",
        "    def loss_gt_(y_true, y_pred):\n",
        "        intersection = K.sum(K.abs(y_true * y_pred), axis=[-3,-2,-1])\n",
        "        dn = K.sum(K.square(y_true) + K.square(y_pred), axis=[-3,-2,-1]) + e\n",
        "        \n",
        "        return - K.mean(2 * intersection / dn, axis=[0,1])\n",
        "    \n",
        "    return loss_gt_\n",
        "\n",
        "def loss_VAE(input_shape, z_mean, z_var, weight_L2=0.1, weight_KL=0.1):\n",
        "    \"\"\"\n",
        "    loss_VAE(input_shape, z_mean, z_var, weight_L2=0.1, weight_KL=0.1)\n",
        "    ------------------------------------------------------\n",
        "    Since keras does not allow custom loss functions to have arguments\n",
        "    other than the true and predicted labels, this function acts as a wrapper\n",
        "    that allows us to implement the custom loss used in the paper. This function\n",
        "    calculates the following equation, except for -L<dice> term. (i.e. VAE decoder part loss)\n",
        "    \n",
        "    L = - L<dice> + weight_L2 ∗ L<L2> + weight_KL ∗ L<KL>\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "     `input_shape`: A 4-tuple, required\n",
        "        The shape of an image as the tuple (c, H, W, D), where c is\n",
        "        the no. of channels; H, W and D is the height, width and depth of the\n",
        "        input image, respectively.\n",
        "    `z_mean`: An keras.layers.Layer instance, required\n",
        "        The vector representing values of mean for the learned distribution\n",
        "        in the VAE part. Used internally.\n",
        "    `z_var`: An keras.layers.Layer instance, required\n",
        "        The vector representing values of variance for the learned distribution\n",
        "        in the VAE part. Used internally.\n",
        "    `weight_L2`: A real number, optional\n",
        "        The weight to be given to the L2 loss term in the loss function. Adjust to get best\n",
        "        results for your task. Defaults to 0.1.\n",
        "    `weight_KL`: A real number, optional\n",
        "        The weight to be given to the KL loss term in the loss function. Adjust to get best\n",
        "        results for your task. Defaults to 0.1.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    loss_VAE_(y_true, y_pred): A custom keras loss function\n",
        "        This function takes as input the predicted and ground labels, uses them\n",
        "        to calculate the L2 and KL loss.\n",
        "        \n",
        "    \"\"\"\n",
        "    def loss_VAE_(y_true, y_pred):\n",
        "        c, H, W, D = input_shape\n",
        "        n = c * H * W * D\n",
        "        \n",
        "        loss_L2 = K.mean(K.square(y_true - y_pred), axis=(1, 2, 3, 4)) # original axis value is (1,2,3,4).\n",
        "\n",
        "        loss_KL = (1 / n) * K.sum(\n",
        "            K.exp(z_var) + K.square(z_mean) - 1. - z_var,\n",
        "            axis=-1\n",
        "        )\n",
        "\n",
        "        return weight_L2 * loss_L2 + weight_KL * loss_KL\n",
        "\n",
        "    return loss_VAE_\n",
        "\n",
        "def build_model(input_shape=(4, 160, 192, 128), output_channels=3, weight_L2=0.1, weight_KL=0.1, dice_e=1e-8):\n",
        "    \"\"\"\n",
        "    build_model(input_shape=(4, 160, 192, 128), output_channels=3, weight_L2=0.1, weight_KL=0.1)\n",
        "    -------------------------------------------\n",
        "    Creates the model used in the BRATS2018 winning solution\n",
        "    by Myronenko A. (https://arxiv.org/pdf/1810.11654.pdf)\n",
        "    Parameters\n",
        "    ----------\n",
        "    `input_shape`: A 4-tuple, optional.\n",
        "        Shape of the input image. Must be a 4D image of shape (c, H, W, D),\n",
        "        where, each of H, W and D are divisible by 2^4, and c is divisible by 4.\n",
        "        Defaults to the crop size used in the paper, i.e., (4, 160, 192, 128).\n",
        "    `output_channels`: An integer, optional.\n",
        "        The no. of channels in the output. Defaults to 3 (BraTS 2018 format).\n",
        "    `weight_L2`: A real number, optional\n",
        "        The weight to be given to the L2 loss term in the loss function. Adjust to get best\n",
        "        results for your task. Defaults to 0.1.\n",
        "    `weight_KL`: A real number, optional\n",
        "        The weight to be given to the KL loss term in the loss function. Adjust to get best\n",
        "        results for your task. Defaults to 0.1.\n",
        "    `dice_e`: Float, optional\n",
        "        A small epsilon term to add in the denominator of dice loss to avoid dividing by\n",
        "        zero and possible gradient explosion. This argument will be passed to loss_gt function.\n",
        "    Returns\n",
        "    -------\n",
        "    `model`: A keras.models.Model instance\n",
        "        The created model.\n",
        "    \"\"\"\n",
        "    c, H, W, D = input_shape\n",
        "    assert len(input_shape) == 4, \"Input shape must be a 4-tuple\"\n",
        "    assert (c % 4) == 0, \"The no. of channels must be divisible by 4\"\n",
        "    assert (H % 16) == 0 and (W % 16) == 0 and (D % 16) == 0, \\\n",
        "        \"All the input dimensions must be divisible by 16\"\n",
        "\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Encoder\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    ## Input Layer\n",
        "    inp = Input(input_shape)\n",
        "\n",
        "    ## The Initial Block\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Input_x1')(inp)\n",
        "\n",
        "    ## Dropout (0.2)\n",
        "    x = SpatialDropout3D(0.2, data_format='channels_first')(x)\n",
        "\n",
        "    ## Green Block x1 (output filters = 32)\n",
        "    x1 = green_block(x, 32, name='x1')\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=2,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Enc_DownSample_32')(x1)\n",
        "\n",
        "    ## Green Block x2 (output filters = 64)\n",
        "    x = green_block(x, 64, name='Enc_64_1')\n",
        "    x2 = green_block(x, 64, name='x2')\n",
        "    x = Conv3D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=2,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Enc_DownSample_64')(x2)\n",
        "\n",
        "    ## Green Blocks x2 (output filters = 128)\n",
        "    x = green_block(x, 128, name='Enc_128_1')\n",
        "    x3 = green_block(x, 128, name='x3')\n",
        "    x = Conv3D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=2,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Enc_DownSample_128')(x3)\n",
        "\n",
        "    ## Green Blocks x4 (output filters = 256)\n",
        "    x = green_block(x, 256, name='Enc_256_1')\n",
        "    x = green_block(x, 256, name='Enc_256_2')\n",
        "    x = green_block(x, 256, name='Enc_256_3')\n",
        "    x4 = green_block(x, 256, name='x4')\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Decoder\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    ## GT (Groud Truth) Part\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    ### Green Block x1 (output filters=128)\n",
        "    x = Conv3D(\n",
        "        filters=128,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_ReduceDepth_128')(x4)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_UpSample_128')(x)\n",
        "    x = Add(name='Input_Dec_GT_128')([x, x3])\n",
        "    x = green_block(x, 128, name='Dec_GT_128')\n",
        "\n",
        "    ### Green Block x1 (output filters=64)\n",
        "    x = Conv3D(\n",
        "        filters=64,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_ReduceDepth_64')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_UpSample_64')(x)\n",
        "    x = Add(name='Input_Dec_GT_64')([x, x2])\n",
        "    x = green_block(x, 64, name='Dec_GT_64')\n",
        "\n",
        "    ### Green Block x1 (output filters=32)\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_ReduceDepth_32')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_GT_UpSample_32')(x)\n",
        "    x = Add(name='Input_Dec_GT_32')([x, x1])\n",
        "    x = green_block(x, 32, name='Dec_GT_32')\n",
        "\n",
        "    ### Blue Block x1 (output filters=32)\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Input_Dec_GT_Output')(x)\n",
        "\n",
        "    ### Output Block\n",
        "    out_GT = Conv3D(\n",
        "        filters=output_channels,  # No. of tumor classes is 3\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        activation='sigmoid',\n",
        "        name='Dec_GT_Output')(x)\n",
        "\n",
        "    ## VAE (Variational Auto Encoder) Part\n",
        "    # -------------------------------------------------------------------------\n",
        "\n",
        "    ### VD Block (Reducing dimensionality of the data)\n",
        "    x = GroupNormalization(groups=8, axis=1, name='Dec_VAE_VD_GN')(x4)\n",
        "    x = Activation('relu', name='Dec_VAE_VD_relu')(x)\n",
        "    x = Conv3D(\n",
        "        filters=16,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=2,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_VD_Conv3D')(x)\n",
        "\n",
        "    # Not mentioned in the paper, but the author used a Flattening layer here.\n",
        "    x = Flatten(name='Dec_VAE_VD_Flatten')(x)\n",
        "    x = Dense(256, name='Dec_VAE_VD_Dense')(x)\n",
        "\n",
        "    ### VDraw Block (Sampling)\n",
        "    z_mean = Dense(128, name='Dec_VAE_VDraw_Mean')(x)\n",
        "    z_var = Dense(128, name='Dec_VAE_VDraw_Var')(x)\n",
        "    x = Lambda(sampling, name='Dec_VAE_VDraw_Sampling')([z_mean, z_var])\n",
        "\n",
        "    ### VU Block (Upsizing back to a depth of 256)\n",
        "    x = Dense((c//4) * (H//16) * (W//16) * (D//16))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Reshape(((c//4), (H//16), (W//16), (D//16)))(x)\n",
        "    x = Conv3D(\n",
        "        filters=256,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_ReduceDepth_256')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_UpSample_256')(x)\n",
        "\n",
        "    ### Green Block x1 (output filters=128)\n",
        "    x = Conv3D(\n",
        "        filters=128,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_ReduceDepth_128')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_UpSample_128')(x)\n",
        "    x = green_block(x, 128, name='Dec_VAE_128')\n",
        "\n",
        "    ### Green Block x1 (output filters=64)\n",
        "    x = Conv3D(\n",
        "        filters=64,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_ReduceDepth_64')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_UpSample_64')(x)\n",
        "    x = green_block(x, 64, name='Dec_VAE_64')\n",
        "\n",
        "    ### Green Block x1 (output filters=32)\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_ReduceDepth_32')(x)\n",
        "    x = UpSampling3D(\n",
        "        size=2,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_UpSample_32')(x)\n",
        "    x = green_block(x, 32, name='Dec_VAE_32')\n",
        "\n",
        "    ### Blue Block x1 (output filters=32)\n",
        "    x = Conv3D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3, 3),\n",
        "        strides=1,\n",
        "        padding='same',\n",
        "        data_format='channels_first',\n",
        "        name='Input_Dec_VAE_Output')(x)\n",
        "\n",
        "    ### Output Block\n",
        "    out_VAE = Conv3D(\n",
        "        filters=4,\n",
        "        kernel_size=(1, 1, 1),\n",
        "        strides=1,\n",
        "        data_format='channels_first',\n",
        "        name='Dec_VAE_Output')(x) \n",
        "\n",
        "    # Build and Compile the model\n",
        "    out = out_GT\n",
        "    model = Model(inp, outputs=[out, out_VAE])  # Create the model\n",
        "    model.compile(\n",
        "        adam(lr=1e-4),\n",
        "        [loss_gt(dice_e), loss_VAE(input_shape, z_mean, z_var, weight_L2=weight_L2, weight_KL=weight_KL)],\n",
        "        metrics=[dice_coefficient]\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "uroBLO7InRnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}